{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T13:51:48.101027Z","iopub.status.busy":"2024-06-27T13:51:48.100713Z","iopub.status.idle":"2024-06-27T13:51:50.261303Z","shell.execute_reply":"2024-06-27T13:51:50.260328Z","shell.execute_reply.started":"2024-06-27T13:51:48.101002Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda:0 device\n"]}],"source":["import re\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn.functional as F\n","from torch import Tensor, nn\n","\n","device = (\n","    \"cuda:0\"\n","    if torch.cuda.is_available()\n","    else \"mps\"\n","    if torch.backends.mps.is_available()\n","    else \"cpu\"\n",")\n","print(f\"Using {device} device\")"]},{"cell_type":"markdown","metadata":{},"source":["## Load Dataset\n","\n","Embed each nt with a 0/1 vector [x,x,x,x]"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T13:51:50.262789Z","iopub.status.busy":"2024-06-27T13:51:50.262369Z","iopub.status.idle":"2024-06-27T13:51:50.269896Z","shell.execute_reply":"2024-06-27T13:51:50.269010Z","shell.execute_reply.started":"2024-06-27T13:51:50.262763Z"},"trusted":true},"outputs":[],"source":["DEG_dict = {   ## degenerative dict\n","    'A':'A',\n","    'U':'U',\n","    'C':'C',\n","    'G':'G',\n","    'R':'AG',\n","    'Y':'CT',\n","    'M':'AC',\n","    'K':'GT',\n","    'S':'GC',\n","    'W':'AT',\n","    'H':'ATC',\n","    'B':'GTC',\n","    'V':'GAC',\n","    'D':'GAT',\n","    'N':'ATCG'\n","    }\n","\n","ORDER = list('AUCG')\n","\n","def embed(nt):\n","    emb = [0 for i in ORDER]\n","    try:\n","        for x in list(DEG_dict[nt]):\n","            emb[ORDER.index(x)] = 1\n","    except:\n","        return [1 for i in ORDER]\n","    return emb\n","\n","\n","def tokenize_embed(seq):\n","    return [embed(nt) for nt in seq]"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T13:51:50.271229Z","iopub.status.busy":"2024-06-27T13:51:50.270969Z","iopub.status.idle":"2024-06-27T13:51:50.292432Z","shell.execute_reply":"2024-06-27T13:51:50.291624Z","shell.execute_reply.started":"2024-06-27T13:51:50.271206Z"},"trusted":true},"outputs":[],"source":["def read_fasta(file):\n","    data_header = []\n","    data_seq = []\n","    with open(file,'r') as f:\n","        while True:\n","            lineH = f.readline().strip()      \n","            lineS = f.readline().strip()   \n","            if not lineS:\n","                break\n","            data_header.append(lineH)\n","            data_seq.append(lineS)\n","    return list(zip(data_header,data_seq)) \n","\n","def header_parser_encoder(header):\n","    if 'Archaea' in header.split(';')[0]:\n","        return 0\n","    else:\n","        assert 'Bacteria' in header.split(';')[0]\n","        return 1\n","\n","\n","def collate_batch(data_batch, dtype=torch.float32):\n","    header_batch, seq_batch = [], []\n","    for header,seq in data_batch:\n","        header_batch.append(header_parser_encoder(header))\n","        seq_batch.append(torch.tensor(tokenize_embed(seq), dtype=dtype))\n","    header_batch = torch.tensor(header_batch, dtype=dtype)\n","    seq_batch = torch.nn.utils.rnn.pad_sequence(seq_batch, padding_value=float(0), batch_first=True) ## padded to equal\n","    return header_batch.to(device),seq_batch.permute(0,2,1).to(device)    ## [batch, embd(channal), seqlen]    "]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T13:51:50.294850Z","iopub.status.busy":"2024-06-27T13:51:50.294577Z","iopub.status.idle":"2024-06-27T13:51:50.381109Z","shell.execute_reply":"2024-06-27T13:51:50.380288Z","shell.execute_reply.started":"2024-06-27T13:51:50.294829Z"},"trusted":true},"outputs":[],"source":["KMER = 10   \n","BATCH_SIZE = 512\n","EMBED_SIZE = 120\n","CLASS_NUM = 2\n","\n","train_dl = torch.utils.data.DataLoader(read_fasta('/kaggle/input/a000000/train.fa'), batch_size=BATCH_SIZE, shuffle=True, \n","                                       collate_fn = lambda x: collate_batch(x, dtype=torch.float32) )"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T13:51:50.382819Z","iopub.status.busy":"2024-06-27T13:51:50.382378Z","iopub.status.idle":"2024-06-27T13:51:50.387277Z","shell.execute_reply":"2024-06-27T13:51:50.386226Z","shell.execute_reply.started":"2024-06-27T13:51:50.382785Z"},"trusted":true},"outputs":[],"source":["# for tt in train_dl:\n","#     break\n","\n","# tt[1].size()\n","# tt[0].size(), tt[1].size(), tt[0][0], tt[1][0]"]},{"cell_type":"markdown","metadata":{},"source":["## Model\n","\n","input: 16S seq\n","\n","output: Archaea/Bacteria\n","\n","\n","CNN --- LSTM --- Classifier\n","\n","Todo: Optimize the model, the current one seems not functioning\n","\n","Todo: Do not input strings, input kmer_abduance_list instead? (for small kmers, or the list could be too huge)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T13:51:50.388627Z","iopub.status.busy":"2024-06-27T13:51:50.388320Z","iopub.status.idle":"2024-06-27T13:51:50.398220Z","shell.execute_reply":"2024-06-27T13:51:50.397388Z","shell.execute_reply.started":"2024-06-27T13:51:50.388604Z"},"trusted":true},"outputs":[],"source":["def train_epoch(dataloader, model, loss_fn, optimizer):\n","    lossSum = 0\n","    correctSum = 0\n","    model.train()                                    ### set training mode\n","    for (header_batch, seq_batch) in dataloader:\n","        pred = model(seq_batch)\n","        # Compute prediction error\n","        loss = loss_fn(pred.squeeze(-1),header_batch)\n","        lossSum += loss.item()\n","        correctSum += (pred.squeeze(-1).ge(1/2) == header_batch).type(torch.float).sum().item()\n","        # Backpropagation\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        print('>',end='')\n","    avgTrainingLoss = lossSum/len(dataloader)\n","    avgTrainingAcc  = correctSum/len(dataloader.dataset)\n","    return avgTrainingLoss,avgTrainingAcc\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T13:51:50.399443Z","iopub.status.busy":"2024-06-27T13:51:50.399203Z","iopub.status.idle":"2024-06-27T13:51:50.411561Z","shell.execute_reply":"2024-06-27T13:51:50.410600Z","shell.execute_reply.started":"2024-06-27T13:51:50.399423Z"},"trusted":true},"outputs":[],"source":["class ClassifierBinary(nn.Module):\n","    def __init__(self, sizeA):  ## out_class=2 is a must\n","        super().__init__()\n","        self.mlp = nn.Sequential(\n","            nn.Linear(sizeA, sizeA),\n","            nn.Dropout(),\n","            nn.ReLU(),\n","            \n","            nn.Linear(sizeA, sizeA),\n","            nn.Dropout(),\n","            nn.ReLU(),\n","            nn.Linear(sizeA, 1),\n","            nn.Sigmoid()\n","        )\n","    def forward(self, x):\n","        return self.mlp(x)\n","\n","\n","class CNN_RNN_Net(nn.Module):\n","    def __init__(self, kmer, out_class):\n","        super().__init__()\n","        self.cnn = nn.Sequential(\n","            nn.Conv1d(in_channels = 4, \n","                      out_channels = 10,\n","                      kernel_size = kmer,\n","                      stride = 2),\n","            nn.MaxPool1d(kernel_size = kmer, stride = 2),\n","            nn.ReLU(),\n","        )\n","        self.lstm = nn.LSTM(\n","            input_size=10, hidden_size=20, num_layers=1, batch_first=True, bidirectional=False\n","        )\n","        self.linearC = ClassifierBinary(20)\n","        \n","    def forward(self, input_batch):\n","        x = self.cnn(input_batch)\n","        x = x.permute(0,2,1)\n","        _, (x, _) = self.lstm(x)\n","        x = x.squeeze(0)\n","        x = self.linearC(x)\n","        return x\n","\n","\n","\n","# for (h,s) in train_dl:\n","#     break\n","\n","# s.size(),CNN_RNN_Net(7,2 )(s).size()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T13:51:50.412999Z","iopub.status.busy":"2024-06-27T13:51:50.412653Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Epoch 1--Training loss:: 0.697205--Training Acc:: 0.499950\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Epoch 2--Training loss:: 0.697040--Training Acc:: 0.500000\n",">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Epoch 3--Training loss:: 0.697684--Training Acc:: 0.500000\n",">>>>>>>>>>>>>>>>>>>>"]}],"source":["Model =  CNN_RNN_Net(KMER, 2).to(device)\n","loss_fn = nn.BCELoss()\n","optimizer = torch.optim.SGD(Model.parameters(), lr=1e-5)\n","\n","epochs = 30\n","for t in range(epochs):\n","    avgTrainingLoss,avgTrainingAcc = train_epoch(train_dl, Model, loss_fn, optimizer)\n","    print(f'Epoch {t+1}--Training loss:: {avgTrainingLoss:>7f}--Training Acc:: {avgTrainingAcc:>7f}') "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5291866,"sourceId":8800131,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":5}
